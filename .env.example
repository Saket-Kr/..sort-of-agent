# LLM Configuration
LLM_PROVIDER=vllm
LLM_BASE_URL=http://localhost:8000/v1
LLM_API_KEY=your-api-key-here
LLM_MODEL_NAME=your-model-name

# Redis Configuration
REDIS_URL=redis://localhost:6379
REDIS_TTL_SECONDS=86400

# Search Services (Perplexity / Legacy)
WEB_SEARCH_API_URL=https://api.perplexity.ai
WEB_SEARCH_API_KEY=your-perplexity-api-key
TASK_BLOCK_SEARCH_URL=http://localhost:8000/api/task-blocks
TASK_BLOCK_SEARCH_API_KEY=your-task-block-api-key

# Search Backend Selection ("perplexity" or "integrated" for web, "legacy" or "integrated" for task block)
WEB_SEARCH_BACKEND=perplexity
TASK_BLOCK_SEARCH_BACKEND=legacy

# Integrated Search Endpoint (only used when backend=integrated)
INTEGRATED_SEARCH_URL=
INTEGRATED_SEARCH_API_KEY=
INTEGRATED_SEARCH_TIMEOUT=30.0
INTEGRATED_WEB_SEARCH_MAX_RESULTS=3
INTEGRATED_WEB_SEARCH_MODEL_TYPE=big
INTEGRATED_TASK_BLOCK_SEARCH_TYPE=llm
INTEGRATED_TASK_BLOCK_IS_REASON_REQUIRED=true
INTEGRATED_ELASTIC_TASK_BLOCK_SIZE=5

# Server Configuration
WS_HOST=0.0.0.0
WS_PORT=8765
REST_PORT=8090
MAX_CONCURRENT_CONNECTIONS=50

# Observability
LANGFUSE_SECRET_KEY=your-langfuse-secret-key
LANGFUSE_PUBLIC_KEY=your-langfuse-public-key
LANGFUSE_HOST=https://cloud.langfuse.com
LOG_LEVEL=INFO
